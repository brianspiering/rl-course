{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dynamic-Programming-Refresher-&amp;-Dynamic-Programming-for-Reinforcement-Learning\" data-toc-modified-id=\"Dynamic-Programming-Refresher-&amp;-Dynamic-Programming-for-Reinforcement-Learning-1\">Dynamic Programming Refresher &amp; Dynamic Programming for Reinforcement Learning</a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-2\">Learning Outcomes</a></span></li><li><span><a href=\"#What-does-&quot;Dynamic-Programming&quot;-(DP)-mean?-\" data-toc-modified-id=\"What-does-&quot;Dynamic-Programming&quot;-(DP)-mean?--3\">What does \"Dynamic Programming\" (DP) mean? </a></span></li><li><span><a href=\"#How-does-Dynamic-Programming-(DP)-work?\" data-toc-modified-id=\"How-does-Dynamic-Programming-(DP)-work?-4\">How does Dynamic Programming (DP) work?</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-5\">Check for understanding</a></span></li><li><span><a href=\"#-Student-Activity\" data-toc-modified-id=\"-Student-Activity-6\"> Student Activity</a></span></li><li><span><a href=\"#The-connection-between-general-Dynamic-Programming-and-Reinforcement-Learning\" data-toc-modified-id=\"The-connection-between-general-Dynamic-Programming-and-Reinforcement-Learning-7\">The connection between general Dynamic Programming and Reinforcement Learning</a></span></li><li><span><a href=\"#Dynamic-programming-for-Reinforcement-Learning\" data-toc-modified-id=\"Dynamic-programming-for-Reinforcement-Learning-8\">Dynamic programming for Reinforcement Learning</a></span></li><li><span><a href=\"#Preview-Lab-3:-Pyramid-Escape\" data-toc-modified-id=\"Preview-Lab-3:-Pyramid-Escape-9\">Preview Lab 3: Pyramid Escape</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-10\">Takeaways</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Dynamic Programming Refresher & Dynamic Programming for Reinforcement Learning</h2></center>\n",
    "<br>\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/travelling_salesman_problem.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- Write a dynamic programming function in Python.\n",
    "- Explain in your own words how dynamic programming (DP) is useful in Reinforcement Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What does \"Dynamic Programming\" (DP) mean? </h2></center>\n",
    " \n",
    "Dynamic (vs. static) - The problem has a sequential component. An dynamical system involves time dependence (e.g., pendulum, flow of water, ecosystems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Programming - Mathematical programming (aka, mathematical optimization). \n",
    "\n",
    "Try to find the best solution to a problem.\n",
    "\n",
    "See also {Integer, Linear, Convex, …} Programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dynamic Programming is an optimization technique for certain type of sequential problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How does Dynamic Programming (DP) work?</h2></center>\n",
    "\n",
    "A method for solving a entire problem by:\n",
    "\n",
    "1. Breaking down the complete problem into smaller related subproblems. \n",
    "1. Remembering the optimal solution to the subproblems.\n",
    "1. Putting the optimal subproblem solutions back together to find a solution to the complete problem.\n",
    "\n",
    "The breaking down of the problem is often recursive. \n",
    "\n",
    "Recall that recursive problems can be transformed into procedural problems by manually managing the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Problem elements:\n",
    "\n",
    "- Related subproblems - Divide the complete problem in overlapping subproblems.\n",
    "- Optimal substructure - Solving subproblems optimally can automatically provide an optimal to the original complete problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reduces computations by storing and reusing partial results (caching).\n",
    "\n",
    "Caching is critically important, one of the most important concepts in software engineering.\n",
    "\n",
    "[A nonprofit spent all fundraising money on a data bill because it did not cache]( https://news.ycombinator.com/item?id=20020095)\n",
    "\n",
    "Dynamic programming is Another example of a divide-and-conquer algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "What are examples of problems that can be solved with dynamic programming (DP)?\n",
    "\n",
    "General types …   \n",
    "Specific examples …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Shortest path - From here to the another point (e.g., graph path)\n",
    "1. Generating sequences that depend previous elements (e.g., Fibonacci)\n",
    "1. Maximizing a sequence (e.g., cumulative sum with the constraints)\n",
    "1. Scheduling problems (e.g., weighted interval scheduling)\n",
    "1. String algorithms (e.g., sequence alignment for DNA)\n",
    "1. Markov decision process (MDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2> Student Activity</h2></center>\n",
    "\n",
    "Solve the following problems with DP:\n",
    "\n",
    "1. Generate a Fibonacci Sequence: `0, 1, 1, 2, 3, 5, 8, 13`\n",
    "1. Find maximum cumulative sum with the constraint of not taking two numbers in a row.\n",
    "```python\n",
    "assert max_constrained([1, 2, 3, 1])     ==  4\n",
    "assert max_constrained([2, 1, 1, 2])     ==  4\n",
    "assert max_constrained([2, 7, 9, 3, 1])  == 12\n",
    "```\n",
    "1. Find the Length of the Longest Increasing Subsequence (LIS) \n",
    "```python\n",
    "assert len_lis([10, 9]) == 1\n",
    "assert len_lis([10, 22, 9]) == 2\n",
    "assert len_lis([10, 22, 9, 10, 21, 50]) == 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Other common DP programming problems:\n",
    "\n",
    "- Given two strings, find the longest common substring.\n",
    "- Find the longest increasing subsequence.\n",
    "- Determine the minimum (or unique) number of ways to make n cents, given coins of denominations less than n cents.\n",
    "- Given a knapsack with a total weight capacity and a list of items with weight w(i) and value v(i), determine the max total value you can carry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import lru_cache \n",
    "\n",
    "@lru_cache()\n",
    "def fib_dp(n_th):\n",
    "    \"Calculate nth Fibonacci number using dynamic programming\"\n",
    "    if n_th == 0: return 0\n",
    "    if n_th == 1: return 1\n",
    "    return fib_dp(n_th-1) + fib_dp(n_th-2)\n",
    "\n",
    "[fib_dp(n_th) for n_th in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Brian’s other solutions to generate Fibonacci Sequence](https://github.com/brianspiering/fibonacci_sequences)\n",
    "\n",
    "There are many ways of applying DP to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def max_constrained(nums):\n",
    "    \"Get maximum cumulative sum with the constraint of not taking two numbers in a row.\"\n",
    "    total_current, total_previous = 0, 0\n",
    "\n",
    "    for n in nums: \n",
    "        total_previous, total_current = total_current, max(total_previous + n, total_current)\n",
    "\n",
    "    return total_current\n",
    "\n",
    "assert max_constrained([1, 2, 3, 1])     ==  4\n",
    "assert max_constrained([2, 1, 1, 2])     ==  4\n",
    "assert max_constrained([2, 7, 9, 3, 1])  == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def len_lis(nums): \n",
    "    n = len(nums)\n",
    "    seq_len = [1]*n # Initialize LIS values for all indexes \n",
    "    \n",
    "    # Compute the length of each increasing subsequence\n",
    "    for i in range(1, n): \n",
    "        for j in range(0, i): \n",
    "            if (nums[i] > nums[j]) and (seq_len[i] < (seq_len[j] + 1)): \n",
    "                seq_len[i] = seq_len[j]+1\n",
    "\n",
    "    return max(seq_len) # Find longest subsequence\n",
    "\n",
    "assert len_lis([10, 9]) == 1\n",
    "assert len_lis([10, 22, 9]) == 2\n",
    "assert len_lis([10, 22, 9, 10, 21, 50]) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Original Source](https://www.geeksforgeeks.org/python-program-for-longest-increasing-subsequence/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<center><h2>The connection between general Dynamic Programming and Reinforcement Learning</h2></center>\n",
    "\n",
    "The goal of RL's is to maximize the cumulative sum of discounted future rewards.\n",
    "\n",
    "A Fibonacci sequence is also a type of cumulative sum.\n",
    "\n",
    "The House Robber just adds a deterministic selection function, `max`, to pick the value moving forward.\n",
    "\n",
    "In fact, some types of Reinforcement Learning are extensions to the House Robber by adding stochastic selection or even a choice (e.g., bandit) to maximize cumulative sum. \n",
    "\n",
    "Just swap out `max` with your own favorite custom function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Dynamic programming for Reinforcement Learning</h2></center>\n",
    "\n",
    "Recall the Value Function:\n",
    "\n",
    "<center><img src=\"images/dp_formula.png\" width=\"75%\"/></center>\n",
    "\n",
    "For the value function of the following:\n",
    "\n",
    "- a policy π\n",
    "- a time step k\n",
    "- a state s\n",
    "\n",
    "is equal to current reward plus:\n",
    "\n",
    "- discounted rate\n",
    "- all possible next future states:\n",
    "    - complete model of probability transition function\n",
    "    - future value of that state\n",
    "\n",
    "Need to visit all possible states (i.e., futures) at least once:\n",
    "\n",
    "<center><img src=\"images/complete.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Preview Lab 3: Pyramid Escape</h2></center>\n",
    "\n",
    "- Not a real Reinforcement Learning problem. It is a simplified problem - The model is deterministic.\n",
    "    - Would be RL if there was randomness in the reward. Each cell is could be a pdf that generates a value.\n",
    "- It is a binary tree problem represented in a list / array. Use indexing to \"walk\" the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Demo of DP for gridworld](https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_dp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Dynamic Programming (DP) is a general method to solve specific kinds of divide-and-conquer problems.\n",
    "- Dynamic Programming (DP) is useful for finding the optimal policy in MDP by recursively, completely, and efficiently searching the space for a policy maximizes the discounted cumulative reward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
