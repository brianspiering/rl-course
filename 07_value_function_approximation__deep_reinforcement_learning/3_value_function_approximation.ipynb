{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Value-Function-Approximation\" data-toc-modified-id=\"Value-Function-Approximation-1\">Value Function Approximation</a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-2\">Learning Outcomes</a></span></li><li><span><a href=\"#Another-Game:-ASCII-Breakout\" data-toc-modified-id=\"Another-Game:-ASCII-Breakout-3\">Another Game: ASCII Breakout</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-4\">Check for understanding</a></span></li><li><span><a href=\"#What-is-tabular-Q-learning?\" data-toc-modified-id=\"What-is-tabular-Q-learning?-5\">What is tabular Q-learning?</a></span></li><li><span><a href=\"#What-are-the-major-limitations-of-tabular-Q-learning?\" data-toc-modified-id=\"What-are-the-major-limitations-of-tabular-Q-learning?-6\">What are the major limitations of tabular Q-learning?</a></span></li><li><span><a href=\"#Value-Function-Approximation-(VFA)\" data-toc-modified-id=\"Value-Function-Approximation-(VFA)-7\">Value Function Approximation (VFA)</a></span></li><li><span><a href=\"#Linear-Value-Function-Approximation-(VFA)\" data-toc-modified-id=\"Linear-Value-Function-Approximation-(VFA)-8\">Linear Value Function Approximation (VFA)</a></span></li><li><span><a href=\"#Linear-Value-Function-Approximation-(VFA)-for-gridworld\" data-toc-modified-id=\"Linear-Value-Function-Approximation-(VFA)-for-gridworld-9\">Linear Value Function Approximation (VFA) for gridworld</a></span></li><li><span><a href=\"#Linear-Regression-Review\" data-toc-modified-id=\"Linear-Regression-Review-10\">Linear Regression Review</a></span></li><li><span><a href=\"#Linear-Regression-Review\" data-toc-modified-id=\"Linear-Regression-Review-11\">Linear Regression Review</a></span></li><li><span><a href=\"#What-is-the-goal-of-Machine-Learning-(ML)?\" data-toc-modified-id=\"What-is-the-goal-of-Machine-Learning-(ML)?-12\">What is the goal of Machine Learning (ML)?</a></span></li><li><span><a href=\"#-The-true-power-of-Value-Function-Approximation-is-Generalization.\" data-toc-modified-id=\"-The-true-power-of-Value-Function-Approximation-is-Generalization.-13\"> The true power of Value Function Approximation is Generalization.</a></span></li><li><span><a href=\"#Value-Function-Approximation-(VFA)-Formalism\" data-toc-modified-id=\"Value-Function-Approximation-(VFA)-Formalism-14\">Value Function Approximation (VFA) Formalism</a></span></li><li><span><a href=\"#Value-Function-Approximation-(VFA)\" data-toc-modified-id=\"Value-Function-Approximation-(VFA)-15\">Value Function Approximation (VFA)</a></span></li><li><span><a href=\"#Value-Function-Approximation-(VFA)\" data-toc-modified-id=\"Value-Function-Approximation-(VFA)-16\">Value Function Approximation (VFA)</a></span></li><li><span><a href=\"#VFA-is-&quot;context&quot;-for-Q-learning\" data-toc-modified-id=\"VFA-is-&quot;context&quot;-for-Q-learning-17\">VFA is \"context\" for Q-learning</a></span></li><li><span><a href=\"#How-VFA-are-updated\" data-toc-modified-id=\"How-VFA-are-updated-18\">How VFA are updated</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-19\">Check for understanding</a></span></li><li><span><a href=\"#(An-incomplete-list-of)-Possible-Functions-for-VFA\" data-toc-modified-id=\"(An-incomplete-list-of)-Possible-Functions-for-VFA-20\">(An incomplete list of) Possible Functions for VFA</a></span></li><li><span><a href=\"#-Life-is-too-short-to-use-Linear-Regression-as-a-VFA\" data-toc-modified-id=\"-Life-is-too-short-to-use-Linear-Regression-as-a-VFA-21\"> Life is too short to use Linear Regression as a VFA</a></span></li><li><span><a href=\"#Value-functions-vs-Policy\" data-toc-modified-id=\"Value-functions-vs-Policy-22\">Value functions vs Policy</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-23\">Check for understanding</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-24\">Takeaways</a></span></li><li><span><a href=\"#Sources-of-Inspiration\" data-toc-modified-id=\"Sources-of-Inspiration-25\">Sources of Inspiration</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-26\">Bonus Material</a></span></li><li><span><a href=\"#State-Aggregation\" data-toc-modified-id=\"State-Aggregation-27\">State Aggregation</a></span></li><li><span><a href=\"#Symmetry-as-Quantization\" data-toc-modified-id=\"Symmetry-as-Quantization-28\">Symmetry as Quantization</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Value Function Approximation</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/warren.jpg\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Quote Source](https://www.chicagotribune.com/news/ct-xpm-1994-09-11-9409110413-story.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- List the major limitations of tabular Q-learning.\n",
    "- Explain how Value Function Approximation can overcome those limits.\n",
    "- Compare and contrast the common methods of Value Function Approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Another Game: ASCII Breakout</h2></center>\n",
    "\n",
    "<center><img src=\"https://www.filfre.net/wp-content/uploads/2012/04/493394-breakout-commodore-pet-cbm-screenshot-since-i-couldn-t-get-300x220.png\" width=\"60%\"/></center>\n",
    "\n",
    "<center><a href=\"https://elgoog.im/breakout/\">Play Breakout with during Google image search (Turn off sound before starting)</a></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "How many (states, action) pairs does ASCII Breakout have?  \n",
    "What are actions?  \n",
    "What are states?  \n",
    "What about the \"ball\" trajectory over time (Moving Up? Moving Down?)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://www.filfre.net/2012/04/this-game-is-over/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is tabular Q-learning?</h2></center>\n",
    "\n",
    "<center><img src=\"images/q_table.png\" width=\"75%\"/></center>\n",
    "Q-values are stored in tabular form.\n",
    "\n",
    "The general tabular form is (States x Actions) with Utilities in the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are the major limitations of tabular Q-learning?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) Q-value table size very quickly scales out of memory (even across distributed computing clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Also, continuous states can __not__ be stored in their raw form in any table. High cardinality discrete data become approximately continuous (e.g., how computers represent numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3) Most importantly - Q-values in tabular form are very precise. However, we might never seen the same precise state with same actions again (sparsity). Thus, slow to learn the value of each state individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Think of the states and branching factors of for the board game of Go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Value Function Approximation (VFA)</h2></center>\n",
    "<br>\n",
    "<br>\n",
    "Use anything other than a lookup table.\n",
    "<br>\n",
    "<br>\n",
    "You can be creative when defining a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><h2>Linear Value Function Approximation (VFA)</h2></center>\n",
    " \n",
    " What about this a model of the Value Function?\n",
    " \n",
    " $$V(s) = w_1•f_1(s) + w_2•f_2(s) + … + w_n•f_n(s) $$\n",
    " \n",
    "A collection features that are weighted.\n",
    " \n",
    "For a given state, a collection of features are individually called. The features values are returned. Then weighted. The result is the estimated value of the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Linear regression (a weighted linear combination of features) to the rescue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Linear Value Function Approximation (VFA) for gridworld</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/wharehouse_rewards.png\" width=\"75%\"/></center>\n",
    "\n",
    "Imagine gridworld that 1,000,000 by 1,000,000.\n",
    "\n",
    "Instead of storing every one those values. Let's generalization across features.\n",
    " \n",
    "What possible features?\n",
    " \n",
    "left-side -> go right\n",
    "lower-side -> go up\n",
    "\n",
    "more left -> go more right\n",
    "more lower -> go more up\n",
    "\n",
    "Learn a simple linear weighting.\n",
    "\n",
    "Since it is linear regression, we have to do the feature engineering by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Linear Regression Review</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/li.png\" width=\"55%\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Linear Regression Review</h2></center>\n",
    "\n",
    "Lossy data compression \n",
    "\n",
    "Input: Many raw points  \n",
    "Output: A few estimated coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><img src=\"https://pediaa.com/wp-content/uploads/2018/08/Difference-Between-Lossy-and-Lossless-Compression-Comparison-Summary.jpg\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><h2>What is the goal of Machine Learning (ML)?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<center>Learn a function from data that can <b>generalize</b> to predict new data.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Anyone who has taken an ML course with me knows that I consider generalization the core promise and problem of ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2> The true power of Value Function Approximation is Generalization.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "An agent does need to see every state to make a reasonable prediction. \n",
    "\n",
    "Can generalize from nearby states.\n",
    "\n",
    "In Linear Regression, that is most commonly interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Value Function Approximation (VFA) Formalism</h2></center>\n",
    "\n",
    "$$\\hat q ( s , a , \\mathbf w ) ≈ q_π ( s , a )$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Using a state-dependent weight vector $w$ to approximate estimate a the value of a policy for a state, action pair.\n",
    "\n",
    "That weight vector and approximate state is much smaller than precise raw states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Value Function Approximation (VFA)</h2></center>\n",
    "\n",
    "\n",
    "The black box takes as input the current state and returns the utility of the state or the state-action utilities.\n",
    "\n",
    "<center><img src=\"images/low_utlity.png\" width=\"75%\"/></center>\n",
    "\n",
    "<center><img src=\"images/q_function.png\" width=\"75%\"/></center>\n",
    "\n",
    "utility function as a music mixer and the vector of weights \n",
    "w as the mixer sliders.\n",
    "\n",
    "\n",
    "<center><img src=\"images/blackbox.png\" width=\"25%\"/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><h2>Value Function Approximation (VFA)</h2></center>\n",
    "\n",
    "<center><img src=\"images/whitebox.png\" width=\"25%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/actions_out.png\" width=\"35%\"/></center>\n",
    "\n",
    "Input: State  \n",
    "Output: An approximate estimate of the value for all possible actions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>VFA is \"context\" for Q-learning</h2></center> \n",
    "\n",
    "<center><img src=\"images/vfa_q.png\" width=\"75%\"/></center>\n",
    "\n",
    "This should look like contextual bandits! \n",
    "\n",
    "The difference is the $s$ drops because a bandit is always in the same state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://www.youtube.com/watch?v=UoPei5o4fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>How VFA are updated</h2></center>\n",
    "\n",
    "<center><img src=\"images/reinforcement_learning_function_approximation_training_cycle.png\" width=\"75%\"/></center>\n",
    "\n",
    "It is a Supervised learning problem.\n",
    "\n",
    "For example, linear regression with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "Take a moment to Brainstorm all possible functions for VFA?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>(An incomplete list of) Possible Functions for VFA</h2></center>\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree, Random Forest, SVM, ... (Any supervised regression technique)\n",
    "- __Deep Learning__\n",
    "- High-order approximators \n",
    "    - Nonlinear\n",
    "    - Fourier / wavelet bases \n",
    "- A technique not yet invented!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<center><img src=\"images/Wavelets-and-function-approximation_W640.jpg\" width=\"35%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Survey of Nonlinear approximation methods](http://people.math.sc.edu/devore/publications/NLACTA.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><h2> Life is too short to use Linear Regression as a VFA</h2></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Do __not__ define a model by hand. You are often __not__ a domain expert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - We do __not__ need to understand / interpret the model, just need to good predictions. Heck - We do __not__ understand / interpret what policy our agent is using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Linear regression needs to explicitly model non-linearities. Deep Learning does it automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Reinforcement Learning has often big (nearly unlimited) data because it happens in a simulated world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our data is often non-stationary, non-iid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Neural networks can train end-to-end, thus better handle non-stationary, non-iid data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Value functions vs Policy</h2></center>\n",
    "\n",
    "Value functions can be very complex for large\n",
    "problems. It is just getting good estimates of what is valuable.\n",
    "\n",
    "While the resulting policies (mapping from state to action) appear simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><h2>Check for understanding</h2></center>\n",
    " \n",
    " What are the 4 biggest limitations of storing values in a lookup table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Table size quickly grows.\n",
    "1. Can not handle continuous states.\n",
    "1. Sparsity - each state might only visited once or a hand-full of times. Most states are never visited.\n",
    "1. Brittle - specific to the precisely observed state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- Q-learning can be made more powerful through Value Function Approximation (VFA)\n",
    "- VFA learns a function to model state, action pairs.\n",
    "- VFA's primary benefit is better ability to generalize to unseen states.\n",
    "- VFA is best done with Deep Learning (assuming you can get enough data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Sources of Inspiration</h2></center>\n",
    "\n",
    "- https://mpatacchiola.github.io/blog/2017/12/11/dissecting-reinforcement-learning-7.html\n",
    "- [David Silver’s lecture VFA](https://www.youtube.com/watch?v=UoPei5o4fps&t=5217s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Material\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>State Aggregation</h2></center>\n",
    "\n",
    "\n",
    "In practice, often have large state space. Each state described by set of features.\n",
    "\n",
    "State Aggregation is decreasing the state/action space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Quantization, aka binning, is common technique.\n",
    "- Learn collections of states, instead of individual states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Typically reduce state space is a stop-gap measure. The Q-value table will just fill up with precise, aggregated values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Symmetry as Quantization</h2></center>\n",
    "<br><br>\n",
    "<center>Which is the best action for O?</center>\n",
    "<center><img src=\"http://ggp.stanford.edu/notes/figures/symmetries.jpg\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Three symmetric positions in Tic-Tac-Toe. A rotation by 180° transforms the position shown on the left-hand side into the center board. Mirroring the latter along the first diagonal results in the position on the right-hand side.\n",
    "\n",
    "We only need to store 1 of these in the Q-value table.\n",
    "\n",
    "This is still precise Value Function.\n",
    "\n",
    "[Source](http://ggp.stanford.edu/notes/chapter_14.html)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
