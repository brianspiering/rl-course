{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Train-Neural-Network-on-the-MNIST-dataset\" data-toc-modified-id=\"Train-Neural-Network-on-the-MNIST-dataset-1\">Train Neural Network on the MNIST dataset</a></span></li><li><span><a href=\"#Define-architecture\" data-toc-modified-id=\"Define-architecture-2\">Define architecture</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-3\">Prepare data</a></span></li><li><span><a href=\"#Define-a-multilayer-perceptron-(MLP)--\" data-toc-modified-id=\"Define-a-multilayer-perceptron-(MLP)---4\">Define a multilayer perceptron (MLP)  </a></span></li><li><span><a href=\"#Train-model\" data-toc-modified-id=\"Train-model-5\">Train model</a></span></li><li><span><a href=\"#Evaluate-model-on-test-data\" data-toc-modified-id=\"Evaluate-model-on-test-data-6\">Evaluate model on test data</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-7\">Check for understanding</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Neural Network on the MNIST dataset\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/mnistExamples.png\" width=\"75%\"/></center>\n",
    "\n",
    "[Based on this code](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<details><summary>\n",
    "What are the high-level steps to build an Image Classification System?\n",
    "</summary>\n",
    "1. Get labeled data <br>\n",
    "2. Define an architecture <br>\n",
    "3. Train <br>\n",
    "4. Test <br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Define architecture\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/mnist_arch.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "Prepare data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using TensorFlow in beta\n",
    "\n",
    "# There is a odd logging error we should ignore\n",
    "# https://github.com/tensorflow/tensorflow/issues/8340#issuecomment-332212742\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/ml_workflow.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and test splits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 60,000\n",
      "Number of test examples:  10,000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train examples: {x_train.shape[0]:,}')\n",
    "print(f'Number of test examples:  {x_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visually inspect a random selection of images\n",
    "for i in range(9):\n",
    "    pyplot.subplot(331 + i) # 331  is a hack for [row, col, index]\n",
    "    pyplot.imshow(x_train[randint(0, x_train.shape[0])], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image matrix into vector to feed into first layer \n",
    "\n",
    "image_size = 784 # 28 x 28  \n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size) # Transform from matrix to vector\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255 # Normalize inputs from 0-255 to 0.0-1.0\n",
    "\n",
    "# All transformation to train data have to be applied to test data\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size) # Transform from matrix to vector\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255 # Normalize inputs from 0-255 to 0.0-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTFM - https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a multilayer perceptron (MLP)  \n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define first hidden layer\n",
    "layer_input = Dense(units=512, \n",
    "                    activation='sigmoid', \n",
    "                    input_shape=(image_size,))\n",
    "model.add(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define another hidden layer\n",
    "layer_input = Dense(units=512, \n",
    "                    activation='sigmoid')\n",
    "model.add(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output layers\n",
    "layer_output = Dense(units=num_classes,\n",
    "                     activation='softmax')\n",
    "\n",
    "model.add(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', # How do we penalize errors? Increases as the predicted probability diverges from the actual label.\n",
    "              optimizer=SGD(), # Stochastic Gradient Descent - More on optimitization day\n",
    "              metrics=['accuracy']) # Number correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Learn more about Cross Entropy__\n",
    "\n",
    "- [Brief intro to common loss functions](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
    "- [A Friendly Introduction to Cross-Entropy Loss](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Train model\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is the number of data examples before a backprop pass\n",
    "batch_size = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<details><summary>\n",
    "Why do we pick 128?\n",
    "</summary>\n",
    "It is a power of 32 which optimizes data loading for common computer architectures.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs is the number of passes over complete dataset\n",
    "epochs = 1 # Try 1 to make sure model works (aka, the linear algebra is correct)\n",
    "# epochs = 10 # Then scale up to small value to make sure model is learning at least a little during each epoch\n",
    "# epochs = 50 # Then do full run which make take hours, days, or even weeks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 2.2668 - accuracy: 0.1982\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 2.1781 - accuracy: 0.4295\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 2.0626 - accuracy: 0.5558\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 1.8924 - accuracy: 0.6217\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 1.6614 - accuracy: 0.6682\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 1.4093 - accuracy: 0.7075\n",
      "Epoch 7/10\n",
      "34432/60000 [================>.............] - ETA: 3s - loss: 1.2345 - accuracy: 0.7373"
     ]
    },
    {
     "ename": "_NotOkStatusException",
     "evalue": "InvalidArgumentError: Error while reading CompositeTensor._type_spec.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_NotOkStatusException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fea0589e5e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2661\u001b[0m           *args, **kwargs)\n\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key\u001b[0;34m(self, args, kwargs, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m   2499\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m       input_signature = pywrap_tensorflow.TFE_Py_EncodeArg(\n\u001b[0;32m-> 2501\u001b[0;31m           inputs, include_tensor_ranks_only)\n\u001b[0m\u001b[1;32m   2502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_NotOkStatusException\u001b[0m: InvalidArgumentError: Error while reading CompositeTensor._type_spec."
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now we wait...__\n",
    "\n",
    "<center><img src=\"images/waiting.jpg\" width=\"35%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on test data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:      1.16\n",
      "Test accuracy: 75.140%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, \n",
    "                                y_test, \n",
    "                                verbose=False)\n",
    "print(f\"Test loss:      {loss:.3}\")\n",
    "print(f\"Test accuracy: {accuracy:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Check for understanding</h2></center>\n",
    "\n",
    "- How well does the model do? Better than chance? Better than humans?\n",
    "- How could the model be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
